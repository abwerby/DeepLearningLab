{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2486696",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exercise Image-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5d5148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T16:47:37.010939Z",
     "start_time": "2023-04-26T16:47:37.006064Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import paths\n",
    "from datasets import VOCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591da245-9ab5-43cc-8df2-17a5c31cd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Image Captioning\n",
    "# Your first task will be to complete the inference code to generate captions for the given VOC dataset.\n",
    "from eval_captioning import extract_evaluate_write_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ce6b3-fd3d-481a-b164-e7731d3d385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Complete Caption Generation with Greedy Search\n",
    "\n",
    "# TODO: In file models/blip/blip_caption.py complete the methods generate and greedy_search. \n",
    "#       Generate and evaluate captions for the VOC dataset. You should get about 28% BLEU score. (2 points)\n",
    "\n",
    "extract_evaluate_write_captions(use_topk_sampling=False, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1455059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T16:47:37.256254Z",
     "start_time": "2023-04-26T16:47:37.192994Z"
    }
   },
   "outputs": [],
   "source": [
    "voc_path = Path(paths.CV_PATH_VOC)\n",
    "dataset = VOCDataset(voc_path, voc_path / \"ImageSets\" / \"Segmentation\" / \"val.txt\",\n",
    "                     load_captions=True)\n",
    "\n",
    "# load and show generated captions\n",
    "# todo update the path to match your experiment\n",
    "pred_captions_file = \"/export/home/werbya/dll/DLL/DL_LAB24_Exercises-3/outputs/eval_captioning/2024_05_26_23_30_14/pred_captions.txt\"\n",
    "with open(pred_captions_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    pred_captions = f.readlines()\n",
    "    \n",
    "from PIL import Image\n",
    "for i in range(10):\n",
    "    data = dataset[i]\n",
    "    display(data[\"image\"])\n",
    "    print(f\"Pred caption: {pred_captions[i]}\")\n",
    "    print(f\"Reference caption: {data['caption']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eceaf88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 1.2 Complete Caption Generation with Sampling\n",
    "# TODO: In file models/blip/blip_caption.py complete the method sampling. \n",
    "#       There, Top-K sampling instead of greedy search is used to select the next token when decoding. \n",
    "#       Evaluate again with Top-K sampling.\n",
    "#       You should get a lower BLEU score of about 7% for temperature τ = 1.0, and about 12% for τ = 0.7. \n",
    "#       Why do the results improve with lower temperature? (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0f95e-95e1-4eaf-b6c4-387268bfc237",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4abaff-6d80-43dc-9e2f-4377b09548b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Prompt Engineering\n",
    "# TODO: Experiment with different prompts (the default prompt is “a picture of ”). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the prompt and the resulting BLEU score in a table for each setting. \n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7, prompt=\"this is a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352c828-0517-482d-a607-278accb7c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Student Hyperparameter Search\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=10, temperature=0.7, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf535e-447d-4493-bd4f-e12731007a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f0cb7-6677-49ed-be36-1891dae6e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Image-Text Retrieval\n",
    "# Your second task will be to train and evaluate the retrieval head of the BLIP model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d87144-6833-4d58-ac2b-9bc8f4e69119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 00:38:47,239 [INFO] Running on device: cuda, cuda available: True\n",
      "2024-05-27 00:38:48,814 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2024-05-27 00:38:48,842 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2024-05-27 00:38:49,159 [INFO] Reshaped position embedding from 196 to 576\n",
      "2024-05-27 00:38:49,241 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2024-05-27 00:38:49,241 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2024-05-27 00:38:49,339 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2024-05-27 00:38:49,516 [INFO] GPU/RAM status: RAM 5.8/125.7 GPU NVIDIA GeForce RTX 3090 Util 3% UMem 0% Mem 1.9/24.0 Temp 35°C\n",
      "2024-05-27 00:38:49,577 [INFO] Output dir: outputs/eval_retrieval/2024_05_27_00_38_49\n",
      "2024-05-27 00:38:49,577 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:17<00:00,  5.11it/s]\n",
      "2024-05-27 00:39:07,579 [INFO] Validation results: {'i_r1': 0.5327812284334024, 'i_r5': 0.8067632850241546, 'i_r10': 0.906832298136646, 'i_medr': 1.0, 'i_meanr': 4.068322981366459, 't_r1': 0.5355417529330573, 't_r5': 0.8184955141476881, 't_r10': 0.8923395445134575, 't_medr': 1.0, 't_meanr': 4.680469289164941}\n",
      "2024-05-27 00:39:07,579 [INFO] Max GPU memory allocated: 1591.402M\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Complete Forward Pass and Evaluate\n",
    "#     Todo: Complete the forward pass in file models/blip/blip_retrieval.py. \n",
    "#           Evaluate your implementation with the provided checkpoint. \n",
    "#           You should get about 54% image-to-text R@1. (2 points)\n",
    "from eval_retrieval import eval_without_args    \n",
    "eval_without_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d4778a-aa46-4933-95c0-98b66b697bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 00:39:14,669 [INFO] Running on device: cuda, cuda available: True\n",
      "2024-05-27 00:39:16,253 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2024-05-27 00:39:16,397 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2024-05-27 00:39:16,717 [INFO] Reshaped position embedding from 196 to 576\n",
      "2024-05-27 00:39:16,796 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2024-05-27 00:39:16,796 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2024-05-27 00:39:16,920 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2024-05-27 00:39:16,920 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2024-05-27 00:39:16,920 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2024-05-27 00:39:16,921 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2024-05-27 00:39:16,921 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2024-05-27 00:39:16,957 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 0% UMem 0% Mem 2.6/24.0 Temp 47°C\n",
      "2024-05-27 00:39:16,957 [INFO] Output dir: outputs/train_retrieval/2024_05_27_00_39_16\n",
      "2024-05-27 00:39:16,958 [INFO] Training epoch 0\n",
      "2024-05-27 00:39:17,247 [INFO]   step: 0 loss: 2.784 lr: 1.000e-03\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:39:17,249 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 68% UMem 33% Mem 2.6/24.0 Temp 51°C\n",
      "2024-05-27 00:39:24,233 [INFO]   step: 10 loss: 1.102 lr: 9.780e-04\n",
      "2024-05-27 00:39:31,628 [INFO]   step: 20 loss: 0.417 lr: 9.560e-04\n",
      "Training:  24%|██▍       | 22/91 [00:15<00:48,  1.43it/s]/export/home/werbya/dll/DLL/DL_LAB24_Exercises-3/models/preprocessing/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative\n",
      "  offset = -low * scale\n",
      "2024-05-27 00:39:38,546 [INFO]   step: 30 loss: 0.610 lr: 9.341e-04\n",
      "2024-05-27 00:39:45,453 [INFO]   step: 40 loss: 0.462 lr: 9.121e-04\n",
      "2024-05-27 00:39:52,272 [INFO]   step: 50 loss: 0.232 lr: 8.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [00:35<00:28,  1.43it/s]2024-05-27 00:39:52,274 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 30% UMem 15% Mem 2.6/24.0 Temp 59°C\n",
      "2024-05-27 00:39:59,554 [INFO]   step: 60 loss: 0.361 lr: 8.681e-04\n",
      "2024-05-27 00:40:06,405 [INFO]   step: 70 loss: 0.362 lr: 8.462e-04\n",
      "2024-05-27 00:40:13,371 [INFO]   step: 80 loss: 0.216 lr: 8.242e-04\n",
      "2024-05-27 00:40:20,529 [INFO]   step: 90 loss: 0.213 lr: 8.022e-04\n",
      "Training: 100%|██████████| 91/91 [01:03<00:00,  1.42it/s]2024-05-27 00:40:20,531 [INFO] Max GPU memory allocated: 1604.650M\n",
      "Training: 100%|██████████| 91/91 [01:03<00:00,  1.43it/s]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:18<00:00,  5.04it/s]\n",
      "2024-05-27 00:40:38,760 [INFO] Validation results: {'i_r1': 0.32091097308488614, 'i_r5': 0.6473429951690821, 'i_r10': 0.7729468599033816, 'i_medr': 3.0, 'i_meanr': 9.102139406487233, 't_r1': 0.3326432022084196, 't_r5': 0.6528640441683919, 't_r10': 0.7701863354037267, 't_medr': 3.0, 't_meanr': 8.952380952380953}\n",
      "2024-05-27 00:40:38,764 [INFO] Training epoch 1\n",
      "2024-05-27 00:40:38,983 [INFO]   step: 0 loss: 0.370 lr: 8.000e-04\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:40:38,985 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 68% UMem 33% Mem 2.6/24.0 Temp 68°C\n",
      "2024-05-27 00:40:41,067 [INFO]   step: 10 loss: 0.152 lr: 7.780e-04\n",
      "2024-05-27 00:40:43,180 [INFO]   step: 20 loss: 0.263 lr: 7.560e-04\n",
      "2024-05-27 00:40:45,278 [INFO]   step: 30 loss: 0.185 lr: 7.341e-04\n",
      "2024-05-27 00:40:47,399 [INFO]   step: 40 loss: 0.180 lr: 7.121e-04\n",
      "2024-05-27 00:40:49,515 [INFO]   step: 50 loss: 0.094 lr: 6.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [00:10<00:08,  4.75it/s]2024-05-27 00:40:49,517 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 64% UMem 30% Mem 2.6/24.0 Temp 72°C\n",
      "2024-05-27 00:40:51,656 [INFO]   step: 60 loss: 0.489 lr: 6.681e-04\n",
      "2024-05-27 00:40:53,711 [INFO]   step: 70 loss: 0.078 lr: 6.462e-04\n",
      "2024-05-27 00:40:55,850 [INFO]   step: 80 loss: 0.091 lr: 6.242e-04\n",
      "2024-05-27 00:40:57,964 [INFO]   step: 90 loss: 0.185 lr: 6.022e-04\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.72it/s]2024-05-27 00:40:57,966 [INFO] Max GPU memory allocated: 1604.650M\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.74it/s]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:18<00:00,  4.99it/s]\n",
      "2024-05-27 00:41:16,415 [INFO] Validation results: {'i_r1': 0.3802622498274672, 'i_r5': 0.6928916494133885, 'i_r10': 0.828847481021394, 'i_medr': 2.0, 'i_meanr': 7.465148378191857, 't_r1': 0.35196687370600416, 't_r5': 0.6928916494133885, 't_r10': 0.8115942028985508, 't_medr': 2.0, 't_meanr': 7.621808143547274}\n",
      "2024-05-27 00:41:16,420 [INFO] Training epoch 2\n",
      "2024-05-27 00:41:16,627 [INFO]   step: 0 loss: 0.102 lr: 6.000e-04\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:41:16,629 [INFO] GPU/RAM status: RAM 6.3/125.7 GPU NVIDIA GeForce RTX 3090 Util 41% UMem 20% Mem 2.6/24.0 Temp 73°C\n",
      "2024-05-27 00:41:18,736 [INFO]   step: 10 loss: 0.273 lr: 5.780e-04\n",
      "2024-05-27 00:41:20,873 [INFO]   step: 20 loss: 0.128 lr: 5.560e-04\n",
      "2024-05-27 00:41:22,968 [INFO]   step: 30 loss: 0.589 lr: 5.341e-04\n",
      "2024-05-27 00:41:25,101 [INFO]   step: 40 loss: 0.276 lr: 5.121e-04\n",
      "2024-05-27 00:41:27,209 [INFO]   step: 50 loss: 0.218 lr: 4.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [00:10<00:08,  4.71it/s]2024-05-27 00:41:27,211 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 66% UMem 31% Mem 2.6/24.0 Temp 76°C\n",
      "2024-05-27 00:41:29,295 [INFO]   step: 60 loss: 0.189 lr: 4.681e-04\n",
      "2024-05-27 00:41:31,375 [INFO]   step: 70 loss: 0.258 lr: 4.462e-04\n",
      "2024-05-27 00:41:33,452 [INFO]   step: 80 loss: 0.300 lr: 4.242e-04\n",
      "2024-05-27 00:41:35,559 [INFO]   step: 90 loss: 0.125 lr: 4.022e-04\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.79it/s]2024-05-27 00:41:35,562 [INFO] Max GPU memory allocated: 1604.650M\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.75it/s]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:18<00:00,  4.97it/s]\n",
      "2024-05-27 00:41:54,064 [INFO] Validation results: {'i_r1': 0.4057971014492754, 'i_r5': 0.7287784679089027, 'i_r10': 0.8440303657694962, 'i_medr': 2.0, 'i_meanr': 6.5231193926846105, 't_r1': 0.40165631469979296, 't_r5': 0.7115251897860594, 't_r10': 0.8371290545203589, 't_medr': 2.0, 't_meanr': 6.799171842650104}\n",
      "2024-05-27 00:41:54,069 [INFO] Training epoch 3\n",
      "2024-05-27 00:41:54,277 [INFO]   step: 0 loss: 0.096 lr: 4.000e-04\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:41:54,280 [INFO] GPU/RAM status: RAM 6.3/125.7 GPU NVIDIA GeForce RTX 3090 Util 10% UMem 5% Mem 2.6/24.0 Temp 76°C\n",
      "2024-05-27 00:41:56,418 [INFO]   step: 10 loss: 0.165 lr: 3.780e-04\n",
      "2024-05-27 00:41:58,556 [INFO]   step: 20 loss: 0.112 lr: 3.560e-04\n",
      "2024-05-27 00:42:00,685 [INFO]   step: 30 loss: 0.171 lr: 3.341e-04\n",
      "2024-05-27 00:42:02,767 [INFO]   step: 40 loss: 0.478 lr: 3.121e-04\n",
      "2024-05-27 00:42:04,854 [INFO]   step: 50 loss: 0.188 lr: 2.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [00:10<00:08,  4.88it/s]2024-05-27 00:42:04,856 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 64% UMem 30% Mem 2.6/24.0 Temp 78°C\n",
      "2024-05-27 00:42:06,972 [INFO]   step: 60 loss: 0.213 lr: 2.681e-04\n",
      "2024-05-27 00:42:09,095 [INFO]   step: 70 loss: 0.166 lr: 2.462e-04\n",
      "2024-05-27 00:42:11,223 [INFO]   step: 80 loss: 0.102 lr: 2.242e-04\n",
      "2024-05-27 00:42:13,359 [INFO]   step: 90 loss: 0.096 lr: 2.022e-04\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.67it/s]2024-05-27 00:42:13,361 [INFO] Max GPU memory allocated: 1604.650M\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.72it/s]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:18<00:00,  4.97it/s]\n",
      "2024-05-27 00:42:31,865 [INFO] Validation results: {'i_r1': 0.4244306418219462, 'i_r5': 0.7467218771566597, 'i_r10': 0.8619737750172533, 'i_medr': 2.0, 'i_meanr': 5.832298136645963, 't_r1': 0.4030365769496204, 't_r5': 0.738440303657695, 't_r10': 0.8530020703933747, 't_medr': 2.0, 't_meanr': 6.273291925465839}\n",
      "2024-05-27 00:42:31,870 [INFO] Training epoch 4\n",
      "2024-05-27 00:42:32,080 [INFO]   step: 0 loss: 0.041 lr: 2.000e-04\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:42:32,082 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 3% UMem 2% Mem 2.6/24.0 Temp 77°C\n",
      "2024-05-27 00:42:34,197 [INFO]   step: 10 loss: 0.258 lr: 1.780e-04\n",
      "2024-05-27 00:42:36,320 [INFO]   step: 20 loss: 0.135 lr: 1.560e-04\n",
      "2024-05-27 00:42:38,462 [INFO]   step: 30 loss: 0.175 lr: 1.341e-04\n",
      "2024-05-27 00:42:40,564 [INFO]   step: 40 loss: 0.104 lr: 1.121e-04\n",
      "2024-05-27 00:42:42,657 [INFO]   step: 50 loss: 0.094 lr: 9.011e-05\n",
      "Training:  55%|█████▍    | 50/91 [00:10<00:08,  4.80it/s]2024-05-27 00:42:42,659 [INFO] GPU/RAM status: RAM 6.4/125.7 GPU NVIDIA GeForce RTX 3090 Util 67% UMem 32% Mem 2.6/24.0 Temp 79°C\n",
      "2024-05-27 00:42:44,746 [INFO]   step: 60 loss: 0.256 lr: 6.813e-05\n",
      "2024-05-27 00:42:46,830 [INFO]   step: 70 loss: 0.144 lr: 4.615e-05\n",
      "2024-05-27 00:42:48,948 [INFO]   step: 80 loss: 0.047 lr: 2.418e-05\n",
      "2024-05-27 00:42:51,061 [INFO]   step: 90 loss: 0.388 lr: 2.198e-06\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.79it/s]2024-05-27 00:42:51,063 [INFO] Max GPU memory allocated: 1604.650M\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.74it/s]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:18<00:00,  4.94it/s]\n",
      "2024-05-27 00:43:09,669 [INFO] Validation results: {'i_r1': 0.43202208419599725, 'i_r5': 0.7605244996549344, 'i_r10': 0.8612836438923396, 'i_medr': 2.0, 'i_meanr': 5.665976535541753, 't_r1': 0.41545893719806765, 't_r5': 0.7398205659075224, 't_r10': 0.8571428571428571, 't_medr': 2.0, 't_meanr': 6.101449275362318}\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Complete Loss and Train from Scratch\n",
    "# Todo: Complete the loss computation in file train_retrieval.py function train_epoch. \n",
    "#       Train the retrieval projection layers from scratch (i.e. from random initialization).\n",
    "#       You should get about 43% image-to-text R@1. (1 point)\n",
    "from train_retrieval import train_retrieval_without_args\n",
    "train_retrieval_without_args(finetune=False, learning_rate=1e-3, weight_decay=1e-3, epochs=5, temperature=0.1)\n",
    "\n",
    "# Optional: start a tensorboard server tensorboard --logdir outputs --port 6006 and watch the experiment in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadb532e-65e3-4e24-8fa9-2a26e3ea6a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 00:43:17,853 [INFO] Running on device: cuda, cuda available: True\n",
      "2024-05-27 00:43:19,395 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2024-05-27 00:43:19,422 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2024-05-27 00:43:19,744 [INFO] Reshaped position embedding from 196 to 576\n",
      "2024-05-27 00:43:19,825 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2024-05-27 00:43:19,826 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2024-05-27 00:43:19,875 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2024-05-27 00:43:19,954 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2024-05-27 00:43:19,955 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2024-05-27 00:43:19,955 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2024-05-27 00:43:19,955 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2024-05-27 00:43:19,955 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2024-05-27 00:43:19,992 [INFO] GPU/RAM status: RAM 6.5/125.7 GPU NVIDIA GeForce RTX 3090 Util 13% UMem 0% Mem 2.6/24.0 Temp 64°C\n",
      "2024-05-27 00:43:20,023 [INFO] Output dir: outputs/train_retrieval/2024_05_27_00_43_19\n",
      "2024-05-27 00:43:20,024 [INFO] Training epoch 0\n",
      "2024-05-27 00:43:20,243 [INFO]   step: 0 loss: 1.563 lr: 1.000e-05\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:43:20,245 [INFO] GPU/RAM status: RAM 6.5/125.7 GPU NVIDIA GeForce RTX 3090 Util 18% UMem 7% Mem 2.6/24.0 Temp 71°C\n",
      "2024-05-27 00:43:22,376 [INFO]   step: 10 loss: 1.682 lr: 9.634e-06\n",
      "2024-05-27 00:43:24,468 [INFO]   step: 20 loss: 1.518 lr: 9.267e-06\n",
      "2024-05-27 00:43:26,554 [INFO]   step: 30 loss: 1.606 lr: 8.901e-06\n",
      "2024-05-27 00:43:28,680 [INFO]   step: 40 loss: 1.568 lr: 8.535e-06\n",
      "2024-05-27 00:43:30,796 [INFO]   step: 50 loss: 1.457 lr: 8.168e-06\n",
      "Training:  55%|█████▍    | 50/91 [00:10<00:08,  4.75it/s]2024-05-27 00:43:30,798 [INFO] GPU/RAM status: RAM 6.6/125.7 GPU NVIDIA GeForce RTX 3090 Util 67% UMem 32% Mem 2.6/24.0 Temp 77°C\n",
      "2024-05-27 00:43:32,892 [INFO]   step: 60 loss: 1.542 lr: 7.802e-06\n",
      "2024-05-27 00:43:35,004 [INFO]   step: 70 loss: 1.414 lr: 7.436e-06\n",
      "2024-05-27 00:43:37,085 [INFO]   step: 80 loss: 1.413 lr: 7.070e-06\n",
      "2024-05-27 00:43:39,201 [INFO]   step: 90 loss: 1.221 lr: 6.703e-06\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.72it/s]2024-05-27 00:43:39,203 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.75it/s]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:18<00:00,  4.90it/s]\n",
      "2024-05-27 00:43:57,972 [INFO] Validation results: {'i_r1': 0.5873015873015873, 'i_r5': 0.8530020703933747, 'i_r10': 0.935127674258109, 'i_medr': 1.0, 'i_meanr': 3.209799861973775, 't_r1': 0.549344375431332, 't_r5': 0.828847481021394, 't_r10': 0.9020013802622499, 't_medr': 1.0, 't_meanr': 4.469979296066253}\n",
      "2024-05-27 00:43:57,977 [INFO] Training epoch 1\n",
      "2024-05-27 00:43:58,198 [INFO]   step: 0 loss: 1.487 lr: 6.667e-06\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:43:58,201 [INFO] GPU/RAM status: RAM 6.6/125.7 GPU NVIDIA GeForce RTX 3090 Util 31% UMem 15% Mem 2.6/24.0 Temp 78°C\n",
      "2024-05-27 00:44:00,319 [INFO]   step: 10 loss: 1.491 lr: 6.300e-06\n",
      "2024-05-27 00:44:02,432 [INFO]   step: 20 loss: 1.318 lr: 5.934e-06\n",
      "2024-05-27 00:44:04,582 [INFO]   step: 30 loss: 1.339 lr: 5.568e-06\n",
      "2024-05-27 00:44:06,712 [INFO]   step: 40 loss: 1.140 lr: 5.201e-06\n",
      "2024-05-27 00:44:08,857 [INFO]   step: 50 loss: 1.224 lr: 4.835e-06\n",
      "Training:  55%|█████▍    | 50/91 [00:10<00:08,  4.63it/s]2024-05-27 00:44:08,859 [INFO] GPU/RAM status: RAM 6.6/125.7 GPU NVIDIA GeForce RTX 3090 Util 64% UMem 30% Mem 2.6/24.0 Temp 79°C\n",
      "2024-05-27 00:44:10,942 [INFO]   step: 60 loss: 1.140 lr: 4.469e-06\n",
      "2024-05-27 00:44:13,074 [INFO]   step: 70 loss: 1.153 lr: 4.103e-06\n",
      "2024-05-27 00:44:15,228 [INFO]   step: 80 loss: 1.268 lr: 3.736e-06\n",
      "2024-05-27 00:44:17,357 [INFO]   step: 90 loss: 1.219 lr: 3.370e-06\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.67it/s]2024-05-27 00:44:17,359 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.70it/s]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:18<00:00,  4.91it/s]\n",
      "2024-05-27 00:44:36,084 [INFO] Validation results: {'i_r1': 0.5873015873015873, 'i_r5': 0.8571428571428571, 'i_r10': 0.9371980676328503, 'i_medr': 1.0, 'i_meanr': 3.1463077984817116, 't_r1': 0.5541752933057281, 't_r5': 0.8302277432712215, 't_r10': 0.9033816425120773, 't_medr': 1.0, 't_meanr': 4.380952380952381}\n",
      "2024-05-27 00:44:36,089 [INFO] Training epoch 2\n",
      "2024-05-27 00:44:36,316 [INFO]   step: 0 loss: 1.204 lr: 3.333e-06\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:44:36,318 [INFO] GPU/RAM status: RAM 6.6/125.7 GPU NVIDIA GeForce RTX 3090 Util 65% UMem 32% Mem 2.6/24.0 Temp 79°C\n",
      "2024-05-27 00:44:38,470 [INFO]   step: 10 loss: 1.325 lr: 2.967e-06\n",
      "2024-05-27 00:44:40,604 [INFO]   step: 20 loss: 1.096 lr: 2.601e-06\n",
      "2024-05-27 00:44:42,760 [INFO]   step: 30 loss: 1.056 lr: 2.234e-06\n",
      "2024-05-27 00:44:44,862 [INFO]   step: 40 loss: 1.330 lr: 1.868e-06\n",
      "2024-05-27 00:44:46,977 [INFO]   step: 50 loss: 1.250 lr: 1.502e-06\n",
      "Training:  55%|█████▍    | 50/91 [00:10<00:08,  4.66it/s]2024-05-27 00:44:46,979 [INFO] GPU/RAM status: RAM 6.6/125.7 GPU NVIDIA GeForce RTX 3090 Util 64% UMem 29% Mem 2.6/24.0 Temp 80°C\n",
      "2024-05-27 00:44:49,123 [INFO]   step: 60 loss: 1.186 lr: 1.136e-06\n",
      "2024-05-27 00:44:51,221 [INFO]   step: 70 loss: 1.226 lr: 7.692e-07\n",
      "2024-05-27 00:44:53,342 [INFO]   step: 80 loss: 1.107 lr: 4.029e-07\n",
      "2024-05-27 00:44:55,484 [INFO]   step: 90 loss: 1.239 lr: 3.663e-08\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.63it/s]2024-05-27 00:44:55,486 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [00:19<00:00,  4.69it/s]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [00:18<00:00,  4.92it/s]\n",
      "2024-05-27 00:45:14,183 [INFO] Validation results: {'i_r1': 0.5928226363008972, 'i_r5': 0.8571428571428571, 'i_r10': 0.937888198757764, 'i_medr': 1.0, 'i_meanr': 3.1497584541062804, 't_r1': 0.5521048999309869, 't_r5': 0.8309178743961353, 't_r10': 0.9033816425120773, 't_medr': 1.0, 't_meanr': 4.349896480331263}\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Finetune instead of Train from Scratch\n",
    "# Todo: Now, try finetuning the head instead with --finetune. \n",
    "#       Set learning rate to 1e-5, weight decay to 0 and train for 3 epochs. \n",
    "#       What score do you get and how can you explain the difference to the score when training from scratch? (1 point)\n",
    "#       Try different search queries. What do you observe?\n",
    "    \n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-5, weight_decay=0, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64660e3d-13a2-4fd9-bea9-bd22f32c3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 00:45:46,437 [INFO] Running on device: cuda, cuda available: True\n",
      "2024-05-27 00:45:47,906 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2024-05-27 00:45:47,934 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2024-05-27 00:45:48,252 [INFO] Reshaped position embedding from 196 to 576\n",
      "2024-05-27 00:45:48,330 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2024-05-27 00:45:48,331 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2024-05-27 00:45:48,467 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2024-05-27 00:45:48,467 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2024-05-27 00:45:48,468 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2024-05-27 00:45:48,468 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2024-05-27 00:45:48,468 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2024-05-27 00:45:48,504 [INFO] GPU/RAM status: RAM 6.6/125.7 GPU NVIDIA GeForce RTX 3090 Util 19% UMem 1% Mem 2.6/24.0 Temp 56°C\n",
      "2024-05-27 00:45:48,504 [INFO] Output dir: outputs/train_retrieval/2024_05_27_00_45_48\n",
      "2024-05-27 00:45:48,505 [INFO] Training epoch 0\n",
      "2024-05-27 00:45:48,716 [INFO]   step: 0 loss: 2.767 lr: 1.000e-04\n",
      "Training:   0%|          | 0/91 [00:00<?, ?it/s]2024-05-27 00:45:48,718 [INFO] GPU/RAM status: RAM 6.6/125.7 GPU NVIDIA GeForce RTX 3090 Util 53% UMem 26% Mem 2.6/24.0 Temp 64°C\n",
      "2024-05-27 00:45:50,767 [INFO]   step: 10 loss: 2.741 lr: 9.978e-05\n",
      "2024-05-27 00:45:52,852 [INFO]   step: 20 loss: 2.689 lr: 9.956e-05\n",
      "2024-05-27 00:45:54,948 [INFO]   step: 30 loss: 2.647 lr: 9.934e-05\n",
      "2024-05-27 00:45:57,004 [INFO]   step: 40 loss: 2.568 lr: 9.912e-05\n",
      "2024-05-27 00:45:59,069 [INFO]   step: 50 loss: 2.456 lr: 9.890e-05\n",
      "Training:  55%|█████▍    | 50/91 [00:10<00:08,  4.84it/s]2024-05-27 00:45:59,071 [INFO] GPU/RAM status: RAM 6.6/125.7 GPU NVIDIA GeForce RTX 3090 Util 70% UMem 33% Mem 2.6/24.0 Temp 74°C\n",
      "2024-05-27 00:46:01,136 [INFO]   step: 60 loss: 2.356 lr: 9.868e-05\n",
      "2024-05-27 00:46:03,188 [INFO]   step: 70 loss: 2.323 lr: 9.846e-05\n",
      "Training:  78%|███████▊  | 71/91 [00:14<00:04,  4.86it/s]"
     ]
    }
   ],
   "source": [
    "# 2.4 Student Hyperparameter Search\n",
    "# Todo: Experiment with different hyperparameters in the random initialization setting (i.e. without finetuning). \n",
    "#       Try at least 3 new hyperparameter settings.\n",
    "#       Note the hyperparameters and the resulting image-to-text R@1 score in a table for each setting. \n",
    "#       Can you improve over the baselines? Add the table to your report. (1 point)\n",
    "\n",
    "train_retrieval_without_args(finetune=False, learning_rate=1e-4, weight_decay=1e-5, epochs=50, temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de0659-9b4b-4875-815a-b58a82cfc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Visualize Top 10 results for a search query.\n",
    "\n",
    "from search_retrieval import get_top10\n",
    "\n",
    "search_query = \"a picture of a plane\"\n",
    "dict_top10 = get_top10(eval_ckpt=None, query = search_query)\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(len(dict_top10[\"id\"])):\n",
    "    image_pil = Image.open(dict_top10[\"fname\"][i])\n",
    "    display(image_pil)\n",
    "    print(f\"Sim. Score: {dict_top10['sim'][i]}\")\n",
    "    print(f\"Caption: {dict_top10['caption'][i]}\")\n",
    "    #print(f\"Name: {dict_top10['name'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb8b9f-1e23-46cb-8784-13d8d8065b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
